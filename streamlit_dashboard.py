import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import numpy as np
from datetime import datetime
import networkx as nx
import os
import sys

# Add subdirectories to the path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
data_dir = os.path.join(parent_dir, 'data')

# If running in the root directory, use data directly
if os.path.exists('data'):
    data_dir = 'data'

# Set page configuration
st.set_page_config(
    page_title="LayerZero Sybil Detection System",
    page_icon="ğŸ•µï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# css styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #FF4B4B;
        text-align: center;
        font-weight: bold;
        margin-bottom: 2rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #FF4B4B;
    }
    .alert-high {
        background-color: #ffebee;
        color: #c62828;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #c62828;
        margin: 1rem 0;
    }
    .alert-success {
        background-color: #e8f5e8;
        color: #2e7d32;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #2e7d32;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Load all analysis data"""
    try:

        scores_file = os.path.join(data_dir, "final_sybil_scores.csv")
        tx_file = os.path.join(data_dir, "layerzero_transactions.csv")
        cluster_file = os.path.join(data_dir, "cluster_analysis_report.json")
        
        # Check if the file exists
        if not os.path.exists(scores_file):
            st.error(f"Risk scores file not found: {scores_file}")
            return None, None, None, False
            
        if not os.path.exists(tx_file):
            st.error(f"Transaction data file not found: {tx_file}")
            return None, None, None, False
            
        if not os.path.exists(cluster_file):
            st.error(f"Cluster analysis file not found: {cluster_file}")
            return None, None, None, False
        
        # Load data
        scores_df = pd.read_csv(scores_file)
        transactions_df = pd.read_csv(tx_file)
        
        # Fix time format conversion issue
        transactions_df['block_timestamp'] = pd.to_datetime(transactions_df['block_timestamp'], errors='coerce')
        
        # Check and remove invalid time data
        valid_timestamps = transactions_df['block_timestamp'].notna()
        if not valid_timestamps.all():
            print(f"Warning: Found {(~valid_timestamps).sum()} invalid time data")
            transactions_df = transactions_df[valid_timestamps]
        
        with open(cluster_file, "r", encoding='utf-8') as f:
            cluster_data = json.load(f)
            
        return scores_df, transactions_df, cluster_data, True
        
    except Exception as e:
        st.error(f"Error loading data: {str(e)}")
        st.info(f"ğŸ“ Current directory: {current_dir}")
        st.info(f"ğŸ“ å‰¯ç›®éŒ„: {parent_dir}")
        st.info(f"ğŸ“ æ•¸æ“šç›®éŒ„: {data_dir}")
        return None, None, None, False

def create_risk_score_charts(scores_df):
    """Create a risk score chart"""
    
    # ç¸½åˆ†åˆ†ä½ˆåœ–
    fig_dist = px.histogram(
        scores_df, 
        x='composite_score', 
        nbins=10,
        title="ğŸ¯ å¥³å·«é¢¨éšªåˆ†æ•¸åˆ†ä½ˆ",
        labels={'composite_score': 'é¢¨éšªåˆ†æ•¸', 'count': 'åœ°å€æ•¸é‡'},
        color_discrete_sequence=['#FF4B4B']
    )
    fig_dist.add_vline(
        x=scores_df['composite_score'].mean(), 
        line_dash="dash", 
        line_color="orange",
        annotation_text=f"å¹³å‡åˆ†æ•¸: {scores_df['composite_score'].mean():.1f}"
    )
    fig_dist.update_layout(height=400)
    
    # çµ„ä»¶åˆ†æ•¸æ¯”è¼ƒ
    component_data = {
        'è·¯å¾‘ç›¸ä¼¼æ€§': scores_df['pathway_score'].mean(),
        'æ™‚é–“å”èª¿æ€§': scores_df['temporal_score'].mean(),
        'è¡Œç‚ºç›¸ä¼¼æ€§': scores_df['behavioral_score'].mean(),
        'ç¶²çµ¡å¯†åº¦': scores_df['network_score'].mean()
    }
    
    fig_components = px.bar(
        x=list(component_data.keys()),
        y=list(component_data.values()),
        title="ğŸ“Š å„çµ„ä»¶å¹³å‡åˆ†æ•¸",
        labels={'x': 'è©•åˆ†çµ„ä»¶', 'y': 'å¹³å‡åˆ†æ•¸'},
        color=list(component_data.values()),
        color_continuous_scale='Reds'
    )
    fig_components.update_layout(height=400, showlegend=False)
    
    # é¢¨éšªç­‰ç´šåˆ†ä½ˆ
    risk_levels = scores_df['risk_level'].str.split(' - ').str[0].value_counts()
    colors = {'CRITICAL': '#FF0000', 'HIGH': '#FF6600', 'MEDIUM': '#FFCC00', 'LOW': '#66CC00', 'MINIMAL': '#00CC66'}
    pie_colors = [colors.get(level, '#CCCCCC') for level in risk_levels.index]
    
    fig_risk = px.pie(
        values=risk_levels.values,
        names=risk_levels.index,
        title="ğŸš¨ é¢¨éšªç­‰ç´šåˆ†ä½ˆ",
        color_discrete_sequence=pie_colors
    )
    fig_risk.update_layout(height=400)
    
    return fig_dist, fig_components, fig_risk

def create_temporal_analysis(transactions_df):
    """å‰µå»ºæ™‚é–“åˆ†æåœ–è¡¨"""
    
    # ç¢ºä¿æ™‚é–“è³‡æ–™æœ‰æ•ˆ
    valid_df = transactions_df.dropna(subset=['block_timestamp']).copy()
    
    if len(valid_df) == 0:
        st.error("æ²’æœ‰æœ‰æ•ˆçš„æ™‚é–“è³‡æ–™")
        return None, None
    
    # æ”¹ç‚ºæœˆåº¦æ´»å‹•ç†±åŠ›åœ– - æ›´æ¸…æ™°çš„å•†æ¥­è¦–è§’
    valid_df['year_month'] = valid_df['block_timestamp'].dt.to_period('M')
    monthly_activity = valid_df.groupby(['year_month', 'address']).size().reset_index(name='tx_count')
    monthly_activity['year_month_str'] = monthly_activity['year_month'].astype(str)
    
    # æŒ‰æœˆä»½çµ±è¨ˆæ´»èºåœ°å€æ•¸
    monthly_summary = valid_df.groupby('year_month').agg({
        'address': 'nunique',
        'guid': 'count'
    }).reset_index()
    monthly_summary.columns = ['month', 'active_addresses', 'total_transactions']
    monthly_summary['month_str'] = monthly_summary['month'].astype(str)
    
    # æ´»èºåœ°å€æœˆåº¦è¶¨å‹¢
    fig_timeline = px.bar(
        monthly_summary,
        x='month_str',
        y='active_addresses',
        title="ğŸ“Š æ¯æœˆæ´»èºåœ°å€æ•¸é‡ - å”èª¿æ”»æ“Šæ™‚é–“ç·š",
        labels={'month_str': 'æœˆä»½', 'active_addresses': 'æ´»èºåœ°å€æ•¸é‡'},
        height=400,
        color='active_addresses',
        color_continuous_scale='Reds'
    )
    fig_timeline.update_layout(
        xaxis_title="æœˆä»½",
        yaxis_title="æ´»èºåœ°å€æ•¸é‡",
        xaxis={'tickangle': 45}
    )
    
    # äº¤æ˜“é‡æœˆåº¦åˆ†ä½ˆ
    fig_frequency = px.line(
        monthly_summary,
        x='month_str',
        y='total_transactions',
        title="ğŸ“ˆ æ¯æœˆäº¤æ˜“é‡è¶¨å‹¢",
        labels={'month_str': 'æœˆä»½', 'total_transactions': 'äº¤æ˜“æ•¸é‡'},
        height=400,
        markers=True,
        line_shape='spline'
    )
    fig_frequency.update_traces(
        line=dict(color='#FF6B6B', width=3),
        marker=dict(size=8, color='#FF6B6B')
    )
    fig_frequency.update_layout(
        xaxis_title="æœˆä»½",
        yaxis_title="äº¤æ˜“æ•¸é‡",
        xaxis={'tickangle': 45}
    )
    
    return fig_timeline, fig_frequency

def create_pathway_analysis(transactions_df):
    """å‰µå»ºè·¯å¾‘åˆ†æåœ–è¡¨ï¼ˆé¡¯ç¤ºéˆåç¨±ï¼‰"""

    # éˆIDå°ç…§è¡¨
    chain_id_map = {
        102: "Binance",
        106: "Avalanche",
        109: "Polygon",
        110: "Arbitrum",
        111: "Optimism",
        112: "Fantom",
        115: "ZKSync",
        116: "Polygon zkEVM",
        125: "Metis",
        129: "ZKFair",
        130: "ZetaChain",
        150: "Manta",
        153: "Mode",
    }

    # "115â†’130" "ZKSync â†’ ZetaChain"
    def format_pathway(path):
        try:
            src, dst = map(int, path.split("â†’"))
            src_name = chain_id_map.get(src, f"EID {src}")
            dst_name = chain_id_map.get(dst, f"EID {dst}")
            return f"{src_name} â†’ {dst_name}"
        except Exception:
            return path

    # â¤ è·¯å¾‘é »ç‡åˆ†æï¼ˆTop 10ï¼‰
    pathway_combos = transactions_df.apply(lambda row: f"{row['src_eid']}â†’{row['dst_eid']}", axis=1)
    pathway_counts = pathway_combos.value_counts().head(10).reset_index()
    pathway_counts.columns = ['pathway', 'count']
    pathway_counts['formatted'] = pathway_counts['pathway'].apply(format_pathway)

    fig_pathways = px.bar(
        pathway_counts,
        x='formatted',
        y='count',
        title="ğŸ›¤ï¸ TOP 10 è·¨éˆè·¯å¾‘ä½¿ç”¨é »ç‡ï¼ˆéˆåç¨±é¡¯ç¤ºï¼‰",
        labels={'formatted': 'è·¨éˆè·¯å¾‘ï¼ˆéˆåç¨±ï¼‰', 'count': 'ä½¿ç”¨æ¬¡æ•¸'},
        height=400,
        color='count',
        color_continuous_scale='Blues'
    )
    fig_pathways.update_layout(showlegend=False, xaxis={'tickangle': 45})

    # â¤ ä¸»è¦å€å¡Šéˆä½¿ç”¨çµ±è¨ˆï¼ˆä¾†æº/ç›®çš„ï¼‰â€” ä¹Ÿé¡¯ç¤ºéˆåç¨±
    chain_mapping = {
        102: "Binance",
        106: "Avalanche",
        109: "Polygon",
        110: "Arbitrum",
        111: "Optimism",
        112: "Fantom",
        115: "ZKSync",
        116: "Polygon zkEVM",
        125: "Metis",
        129: "ZKFair",
        130: "ZetaChain",
        150: "Manta",
        153: "Mode",
        30101: "Ethereum",
        30102: "BNB Chain",
        30106: "Avalanche",
        30109: "Polygon",
        30110: "Arbitrum",
        30111: "Optimism",
        30112: "Fantom",
        30116: "Core",
        30125: "Celo",
        30183: "Linea",
        30184: "Base",
        30195: "Mantle",
    }

    # Count the number of times each chain is used as a source chain and a target chain (Top 8)
    src_chains = transactions_df['src_eid'].value_counts().head(8)
    dst_chains = transactions_df['dst_eid'].value_counts().head(8)

    chain_stats = []
    all_eids = set(src_chains.index) | set(dst_chains.index)
    for eid in all_eids:
        chain_name = chain_mapping.get(eid, f"EID {eid}")
        chain_stats.append({
            'chain': chain_name,
            'source_txs': int(src_chains.get(eid, 0)),
            'destination_txs': int(dst_chains.get(eid, 0)),
            'total': int(src_chains.get(eid, 0)) + int(dst_chains.get(eid, 0))
        })

    chain_stats = sorted(chain_stats, key=lambda x: x['total'], reverse=True)[:8]
    chain_df = pd.DataFrame(chain_stats)

    fig_chains = px.bar(
        chain_df,
        x='chain',
        y=['source_txs', 'destination_txs'],
        title="ğŸ”— ä¸»è¦å€å¡Šéˆä½¿ç”¨çµ±è¨ˆï¼ˆéˆåç¨±ï¼‰",
        labels={'value': 'äº¤æ˜“æ•¸é‡', 'chain': 'å€å¡Šéˆ'},
        height=400,
        color_discrete_map={'source_txs': '#FF6B6B', 'destination_txs': '#4ECDC4'}
    )
    fig_chains.update_layout(
        legend=dict(title="é¡å‹", orientation="h", y=1.02, x=0),
        xaxis={'tickangle': 45}
    )

    return fig_pathways, fig_chains



def create_network_graph(scores_df):
    """å‰µå»ºç¶²çµ¡é—œä¿‚åœ– - å•†æ¥­å‹å¥½ç‰ˆæœ¬"""
    
    # åªé¡¯ç¤ºé«˜é¢¨éšªåœ°å€çš„ç¶²çµ¡é—œä¿‚
    high_risk_df = scores_df[scores_df['composite_score'] >= 75].copy()  # åªå–é«˜é¢¨éšªåœ°å€
    
    if len(high_risk_df) == 0:
        st.warning("æ²’æœ‰è¶³å¤ çš„é«˜é¢¨éšªåœ°å€ä¾†å»ºç«‹ç¶²çµ¡åœ–")
        return None
    
    # å»ºç«‹ç°¡åŒ–çš„ç¶²çµ¡åœ–
    G = nx.Graph()
    
    # æ·»åŠ ç¯€é» - æŒ‰é¢¨éšªç­‰ç´šåˆ†çµ„
    risk_groups = high_risk_df.groupby('risk_level')
    
    # ç‚ºä¸åŒé¢¨éšªç­‰ç´šè¨­ç½®ä¸åŒé¡è‰²å’Œå¤§å°
    risk_colors = {
        'CRITICAL - æ¥µé«˜å¥³å·«é¢¨éšª': '#FF0000',
        'HIGH - é«˜å¥³å·«é¢¨éšª': '#FF6600',
        'MEDIUM - ä¸­ç­‰å¥³å·«é¢¨éšª': '#FFCC00'
    }
    
    # è¨ˆç®—å¸ƒå±€
    pos = {}
    y_offset = 0
    
    for risk_level, group in risk_groups:
        group_size = len(group)
        for i, (_, row) in enumerate(group.iterrows()):
            addr_short = row['address'][:8] + '...'
            G.add_node(addr_short, 
                      score=row['composite_score'],
                      risk_level=risk_level,
                      full_address=row['address'])
            
            # æŒ‰é¢¨éšªç­‰ç´šåˆ†å±¤æ’åˆ—
            x = (i - group_size/2) * 0.3
            pos[addr_short] = (x, y_offset)
        
        y_offset -= 1.5
    
    # æ·»åŠ é‚Š - åªé€£æ¥é¢¨éšªåˆ†æ•¸ç›¸è¿‘çš„åœ°å€
    nodes = list(G.nodes())
    for i, node1 in enumerate(nodes):
        for node2 in nodes[i+1:]:
            score1 = G.nodes[node1]['score']
            score2 = G.nodes[node2]['score']
            if abs(score1 - score2) <= 5:  # åˆ†æ•¸ç›¸è¿‘çš„åœ°å€é€£æ¥
                G.add_edge(node1, node2)
    
    # å‰µå»º Plotly åœ–è¡¨
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
    
    # æº–å‚™ç¯€é»è³‡æ–™
    node_trace = []
    for risk_level, color in risk_colors.items():
        nodes_in_level = [n for n in G.nodes() if G.nodes[n]['risk_level'] == risk_level]
        if nodes_in_level:
            x_coords = [pos[node][0] for node in nodes_in_level]
            y_coords = [pos[node][1] for node in nodes_in_level]
            scores = [G.nodes[node]['score'] for node in nodes_in_level]
            
            node_trace.append(go.Scatter(
                x=x_coords, y=y_coords,
                mode='markers+text',
                marker=dict(
                    size=[15 + score/10 for score in scores],  # åˆ†æ•¸è¶Šé«˜ï¼Œç¯€é»è¶Šå¤§
                    color=color,
                    line=dict(width=2, color='black')
                ),
                text=nodes_in_level,
                textposition="middle center",
                textfont=dict(size=10, color='white'),
                name=risk_level.split(' - ')[0],
                hovertemplate='åœ°å€: %{text}<br>é¢¨éšªåˆ†æ•¸: %{customdata}<extra></extra>',
                customdata=scores
            ))
    
    # å‰µå»ºåœ–è¡¨
    fig = go.Figure()
    
    # æ·»åŠ é‚Š
    fig.add_trace(go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=1, color='lightgray'),
        hoverinfo='none',
        mode='lines',
        showlegend=False
    ))
    
    # æ·»åŠ ç¯€é»
    for trace in node_trace:
        fig.add_trace(trace)
    
    fig.update_layout(
        title="é«˜é¢¨éšªå¥³å·«åœ°å€é—œè¯ç¶²çµ¡",
        showlegend=True,
        hovermode='closest',
        margin=dict(b=20,l=5,r=5,t=40),
        annotations=[
            dict(
                text="ç¯€é»å¤§å°è¡¨ç¤ºé¢¨éšªåˆ†æ•¸ï¼Œé¡è‰²è¡¨ç¤ºé¢¨éšªç­‰ç´š",
                showarrow=False,
                xref="paper", yref="paper",
                x=0.005, y=-0.002,
                xanchor='left', yanchor='bottom',
                font=dict(color='gray', size=12)
            )
        ],
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        height=500,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    return fig

def main():
    # ä¸»æ¨™é¡Œ
    st.markdown('<h1 class="main-header">ğŸ•µï¸ LayerZero Sybil Detection System</h1>', unsafe_allow_html=True)

    
    # è¼‰å…¥æ•¸æ“š
    scores_df, transactions_df, cluster_data, data_loaded = load_data()
    
    if not data_loaded:
        st.error("âŒ ç„¡æ³•è¼‰å…¥æ•¸æ“š")
        
        # é¡¯ç¤ºä¸€å€‹åŸºæœ¬çš„æ¼”ç¤ºç•Œé¢
        st.markdown("---")
        st.subheader("ğŸ­ æ¼”ç¤ºæ¨¡å¼")
        st.info("ä»¥ä¸‹æ˜¯åŸºæ–¼çœŸå¯¦åˆ†æçµæœçš„æ¼”ç¤ºæ•¸æ“š")
        
        # å‰µå»ºæ¼”ç¤ºæ•¸æ“š
        demo_metrics = {
            "æª¢æ¸¬åœ°å€": "20",
            "æ™‚é–“ç¯„åœ": "2022/12/30 - 2024/5/17",
            "è³‡æ–™ä¾†æº": "LayerZero Scan API",
            "å¥³å·«ç¢ºèªç‡": "100%", 
            "å¹³å‡é¢¨éšªåˆ†æ•¸": "86.2/100",
            "æ”»æ“Šæ™‚é–“è·¨åº¦": "1.5å°æ™‚",
            "ç›¸åŒè·¯å¾‘åœ°å€": "20/20"
        }
        
        cols = st.columns(len(demo_metrics))
        for i, (key, value) in enumerate(demo_metrics.items()):
            with cols[i]:
                st.metric(key, value)
        
        return
    
    # å´é‚Šæ¬„
    
    # åˆ†ææ¦‚è¦½
    st.sidebar.markdown("### åˆ†ææ¦‚è¦½")
    st.sidebar.metric("ç¸½æª¢æ¸¬åœ°å€", len(scores_df))
    st.sidebar.metric("ç¸½äº¤æ˜“æ•¸", len(transactions_df))
    st.sidebar.metric("å¹³å‡é¢¨éšªåˆ†æ•¸", f"{scores_df['composite_score'].mean():.1f}/100")
    st.sidebar.metric("æœ€é«˜é¢¨éšªåˆ†æ•¸", f"{scores_df['composite_score'].max()}/100")
    
    # è³‡æ–™é›†è³‡è¨Š
    st.sidebar.markdown("### Dataset Information")
    st.sidebar.markdown("**Time**: 2022/12/30 - 2024/5/17")
    st.sidebar.markdown("**Sources**: LayerZero Scan API")
        
    # é¢¨éšªç­‰ç´šçµ±è¨ˆ
    risk_distribution = scores_df['risk_level'].str.split(' - ').str[0].value_counts()
    st.sidebar.markdown("### ğŸš¨ é¢¨éšªç­‰ç´šåˆ†ä½ˆ")
    for level, count in risk_distribution.items():
        percentage = (count / len(scores_df)) * 100
        if level == "HIGH":
            st.sidebar.markdown(f"ğŸ”´ **{level}**: {count} ({percentage:.1f}%)")
        elif level == "CRITICAL":
            st.sidebar.markdown(f"ğŸš¨ **{level}**: {count} ({percentage:.1f}%)")
        else:
            st.sidebar.markdown(f"ğŸŸ¡ **{level}**: {count} ({percentage:.1f}%)")
    
    # ä¸»é é¢æ¨™ç±¤
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ é¢¨éšªåˆ†æ", "â° æ™‚é–“æ¨¡å¼", "ğŸ›¤ï¸ è·¯å¾‘åˆ†æ", "ğŸ“ å®Œæ•´é¢¨éšªè©•ä¼°åˆ—è¡¨"])
    with tab1:
        
        # å‰µå»ºé¢¨éšªåˆ†æ•¸åœ–è¡¨
        fig_dist, fig_components, fig_risk = create_risk_score_charts(scores_df)
        
        col1, col2 = st.columns(2)
        with col1:
            st.plotly_chart(fig_dist, use_container_width=True)
        with col2:
            st.plotly_chart(fig_risk, use_container_width=True)
        
        st.plotly_chart(fig_components, use_container_width=True)
        
        # TOP é¢¨éšªåœ°å€è¡¨æ ¼
        st.subheader("ğŸ† TOP 10 æœ€é«˜é¢¨éšªåœ°å€")
        top_addresses = scores_df.nlargest(10, 'composite_score')[
            ['address', 'composite_score', 'risk_level', 'confidence', 
             'pathway_score', 'temporal_score', 'behavioral_score', 'network_score']
        ].round(1)
        
        st.dataframe(top_addresses, use_container_width=True)
    
    with tab2:
        
        # å‰µå»ºæ™‚é–“åˆ†æåœ–è¡¨
        fig_timeline, fig_frequency = create_temporal_analysis(transactions_df)
        
        st.plotly_chart(fig_timeline, use_container_width=True)
        st.plotly_chart(fig_frequency, use_container_width=True)
    
    with tab3:
        
        # å‰µå»ºè·¯å¾‘åˆ†æåœ–è¡¨
        fig_pathways, fig_chains = create_pathway_analysis(transactions_df)
        
        st.plotly_chart(fig_pathways, use_container_width=True)
        st.plotly_chart(fig_chains, use_container_width=True)
    
    with tab4:

        # æ·»åŠ ä¸‹è¼‰æŒ‰éˆ•
        csv_data = scores_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±å‘Š (CSV)",
            data=csv_data,
            file_name=f"sybil_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

        # é¡¯ç¤ºå®Œæ•´è¡¨æ ¼
        st.dataframe(scores_df, use_container_width=True)


if __name__ == "__main__":
    main()