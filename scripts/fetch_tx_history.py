import pandas as pd
import requests
import time
import logging
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import os

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class LayerZeroTxFetcher:
    def __init__(self, rate_limit=3):
        """
        LayerZero äº¤æ˜“æ­·å²æŠ“å–å™¨
        rate_limit: æ¯ç§’æœ€å¤§è«‹æ±‚æ•¸
        """
        self.rate_limit = rate_limit
        self.base_url = "https://scan.layerzero-api.com/v1"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'LayerZero-Sybil-Analysis/1.0',
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        })
        
        # LayerZero ä¸»è¦éˆ ID æ˜ å°„ (EID - Endpoint ID)
        self.eid_mapping = {
            30101: "Ethereum",
            30102: "BNB Chain", 
            30106: "Avalanche",
            30109: "Polygon",
            30110: "Arbitrum",
            30111: "Optimism",
            30112: "Fantom",
            30183: "Linea",
            30184: "Base",
            30125: "Celo",
        }
    
    def get_wallet_transactions(self, address, limit=100):
        """
        ä½¿ç”¨æ­£ç¢ºçš„ LayerZero Scan API æŠ“å–éŒ¢åŒ…äº¤æ˜“
        """
        try:
            # ä½¿ç”¨ wallet API endpoint
            url = f"{self.base_url}/messages/wallet/{address.lower()}"
            
            params = {
                'limit': limit
            }
            
            response = self.session.get(url, params=params, timeout=30)
            time.sleep(1/self.rate_limit)  # é€Ÿç‡é™åˆ¶
            
            if response.status_code == 200:
                data = response.json()
                return self._parse_wallet_response(address, data)
            elif response.status_code == 404:
                # åœ°å€æ²’æœ‰ LayerZero äº¤æ˜“è¨˜éŒ„
                logging.info(f"ğŸ“­ {address}: æ²’æœ‰ LayerZero äº¤æ˜“è¨˜éŒ„")
                return []
            else:
                logging.warning(f"API éŒ¯èª¤ {response.status_code} for {address}")
                return []
                
        except Exception as e:
            logging.error(f"æŠ“å– {address} äº¤æ˜“å¤±æ•—: {str(e)}")
            return []
    
    def _parse_wallet_response(self, address, data):
        """è§£æ LayerZero API éŒ¢åŒ…å›æ‡‰"""
        transactions = []
        
        if 'data' in data and data['data']:
            for message in data['data']:
                try:
                    # è§£æåŸºæœ¬è³‡è¨Š
                    pathway = message.get('pathway', {})
                    source = message.get('source', {})
                    destination = message.get('destination', {})
                    source_tx = source.get('tx', {})
                    dest_tx = destination.get('tx', {})
                    
                    transaction = {
                        'address': address.lower(),
                        'guid': message.get('guid', ''),
                        'src_tx_hash': source_tx.get('txHash', ''),
                        'dst_tx_hash': dest_tx.get('txHash', ''),
                        'src_eid': pathway.get('srcEid'),
                        'dst_eid': pathway.get('dstEid'),
                        'src_chain': self.eid_mapping.get(pathway.get('srcEid'), f"EID_{pathway.get('srcEid')}"),
                        'dst_chain': self.eid_mapping.get(pathway.get('dstEid'), f"EID_{pathway.get('dstEid')}"),
                        'nonce': pathway.get('nonce'),
                        'status': message.get('status', {}).get('name', ''),
                        'source_status': source.get('status', ''),
                        'dest_status': destination.get('status', ''),
                        'block_timestamp': source_tx.get('blockTimestamp'),
                        'block_number': source_tx.get('blockNumber'),
                        'from_address': source_tx.get('from', ''),
                        'value': source_tx.get('value', '0'),
                        'created': message.get('created', ''),
                        'updated': message.get('updated', ''),
                        'sender_address': pathway.get('sender', {}).get('address', ''),
                        'receiver_address': pathway.get('receiver', {}).get('address', ''),
                        'pathway_id': pathway.get('id', '')
                    }
                    transactions.append(transaction)
                except Exception as e:
                    logging.warning(f"è§£æäº¤æ˜“å¤±æ•—: {str(e)}")
                    continue
        
        return transactions
    
    def fetch_batch_transactions(self, addresses, batch_size=20, max_workers=3):
        """
        æ‰¹é‡æŠ“å–å¤šå€‹åœ°å€çš„äº¤æ˜“æ­·å²
        æ¸›å°‘ä½µç™¼æ•¸å’Œæ‰¹æ¬¡å¤§å°ä»¥é¿å… API é™åˆ¶
        """
        all_transactions = []
        addresses_with_txs = 0
        
        # åˆ†æ‰¹è™•ç†
        for i in range(0, len(addresses), batch_size):
            batch = addresses[i:i+batch_size]
            logging.info(f"è™•ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(addresses)+batch_size-1)//batch_size}, åœ°å€æ•¸é‡: {len(batch)}")
            
            # å¤šç·šç¨‹è™•ç†ï¼ˆæ¸›å°‘ä½µç™¼æ•¸ï¼‰
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_address = {
                    executor.submit(self.get_wallet_transactions, addr): addr 
                    for addr in batch
                }
                
                for future in as_completed(future_to_address):
                    address = future_to_address[future]
                    try:
                        transactions = future.result()
                        if transactions:
                            all_transactions.extend(transactions)
                            addresses_with_txs += 1
                            logging.info(f"âœ… {address}: {len(transactions)} ç­†äº¤æ˜“")
                        else:
                            logging.info(f"ğŸ“­ {address}: ç„¡äº¤æ˜“è¨˜éŒ„")
                    except Exception as e:
                        logging.error(f"âŒ {address}: {str(e)}")
            
            # æ¯æ‰¹æ¬¡é–“æš«åœæ›´é•·æ™‚é–“
            time.sleep(3)
        
        logging.info(f"ğŸ¯ ç¸½çµ: {addresses_with_txs}/{len(addresses)} å€‹åœ°å€æœ‰ LayerZero äº¤æ˜“")
        return all_transactions
    
    def save_transactions(self, transactions, filename="data/layerzero_transactions.csv"):
        """å„²å­˜äº¤æ˜“è³‡æ–™"""
        if not transactions:
            logging.warning("æ²’æœ‰äº¤æ˜“è³‡æ–™å¯ä»¥å„²å­˜")
            return None
        
        df = pd.DataFrame(transactions)
        
        # è³‡æ–™æ¸…ç†å’Œæ ¼å¼åŒ–
        if 'block_timestamp' in df.columns:
            df['block_timestamp'] = pd.to_datetime(df['block_timestamp'], unit='s', errors='coerce')
        
        if 'created' in df.columns:
            df['created'] = pd.to_datetime(df['created'], errors='coerce')
        
        if 'updated' in df.columns:
            df['updated'] = pd.to_datetime(df['updated'], errors='coerce')
        
        # å„²å­˜ CSV
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        df.to_csv(filename, index=False)
        
        logging.info(f"ğŸ’¾ {len(df)} ç­†äº¤æ˜“å·²å„²å­˜è‡³ {filename}")
        
        return df
    
    def generate_summary_stats(self, df):
        """ç”Ÿæˆçµ±è¨ˆæ‘˜è¦"""
        if df is None or len(df) == 0:
            return {}
        
        stats = {
            'total_transactions': len(df),
            'unique_addresses': df['address'].nunique(),
            'unique_chains': df[['src_chain', 'dst_chain']].stack().nunique(),
            'status_distribution': df['status'].value_counts().to_dict(),
            'chain_pairs': df.groupby(['src_chain', 'dst_chain']).size().to_dict(),
            'date_range': {
                'earliest': df['block_timestamp'].min(),
                'latest': df['block_timestamp'].max()
            } if 'block_timestamp' in df.columns else None,
            'top_pathways': df['pathway_id'].value_counts().head(5).to_dict()
        }
        
        return stats

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""

    # è¨­å®šå„²å­˜è·¯å¾‘
    output_folder = "new_data"
    os.makedirs(output_folder, exist_ok=True)

    # é…ç½®åˆ†æè¦æ¨¡
    ANALYSIS_CONFIG = {
        'address_count': 10000,
        'batch_size': 20,
        'max_workers': 3,
        'rate_limit': 3
    }

    # 1. è®€å–æ¸…ç†å¾Œçš„åœ°å€æ¸…å–®
    try:
        df_addresses = pd.read_csv("data/sybil_addresses_clean.csv")
        addresses = df_addresses['address'].tolist()
        logging.info(f"ğŸ“– è¼‰å…¥ {len(addresses)} å€‹åœ°å€")
    except FileNotFoundError:
        logging.error("âŒ æ‰¾ä¸åˆ°åœ°å€æ¸…å–®")
        return

    # 2. åˆå§‹åŒ–æŠ“å–å™¨
    fetcher = LayerZeroTxFetcher(rate_limit=ANALYSIS_CONFIG['rate_limit'])

    # 3. é¸æ“‡åˆ†æåœ°å€æ•¸é‡
    test_addresses = addresses[:ANALYSIS_CONFIG['address_count']]

    logging.info(f"ğŸ¯ åˆ†ææ¨¡å¼ï¼š{len(test_addresses)} å€‹åœ°å€")
    estimated_minutes = len(test_addresses) * 2.5 / 60
    logging.info(f"â±ï¸  é ä¼°æ™‚é–“ï¼š{estimated_minutes:.1f} åˆ†é˜")

    # 4. æŠ“å–äº¤æ˜“è³‡æ–™
    transactions = fetcher.fetch_batch_transactions(
        test_addresses, 
        batch_size=ANALYSIS_CONFIG['batch_size'],
        max_workers=ANALYSIS_CONFIG['max_workers']
    )

    # 5. å„²å­˜çµæœ
    if transactions:
        tx_path = os.path.join(output_folder, "layerzero_transactions.csv")
        df_tx = fetcher.save_transactions(transactions, filename=tx_path)

        stats = fetcher.generate_summary_stats(df_tx)

        stats_path = os.path.join(output_folder, "fetch_stats.csv")
        stats_df = pd.DataFrame([{
            'timestamp': datetime.now(),
            'addresses_tested': len(test_addresses),
            'addresses_with_txs': stats.get('unique_addresses', 0),
            'total_transactions': stats.get('total_transactions', 0),
            'success_rate': f"{(stats.get('unique_addresses', 0)/len(test_addresses)*100):.1f}%"
        }])
        stats_df.to_csv(stats_path, index=False)

        logging.info(f"ğŸ“‹ çµ±è¨ˆå ±å‘Šå·²å„²å­˜è‡³ {stats_path}")
    else:
        logging.warning("âš ï¸ ç„¡æˆåŠŸæŠ“å–ä»»ä½•äº¤æ˜“è³‡æ–™")

        
        # æä¾›ä¸‹ä¸€æ­¥å»ºè­°
        print("\n" + "="*60)
        print("ğŸ’¡ å»ºè­°çš„æ›¿ä»£æ–¹æ¡ˆ:")
        print("="*60)
        print("1. é€™äº›åœ°å€å¯èƒ½æ²’æœ‰ LayerZero è·¨éˆæ´»å‹•")
        print("2. å¯ä»¥è€ƒæ…®ä½¿ç”¨å…¶ä»– API (å¦‚ Etherscan) ç²å–ä¸€èˆ¬äº¤æ˜“")
        print("3. æª¢æŸ¥åœ°å€æ˜¯å¦åƒèˆ‡å…¶ä»–å”è­°çš„æ´»å‹•")
        print("4. å¢åŠ æ¸¬è©¦åœ°å€æ•¸é‡æˆ–æª¢æŸ¥ä¸åŒæ™‚é–“æ®µ")
        print("="*60)

if __name__ == "__main__":
    main()